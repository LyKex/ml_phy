{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbCfDzn6fk7_"
      },
      "source": [
        "# ML4Phys 2023 Assignment 3\n",
        "## Guoyuan Liu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVu1SzC6f9OV"
      },
      "source": [
        "(e.g. your acknowledgements of others here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp0gbNqhL4TO",
        "outputId": "458b6425-38ca-4c66-fd3f-b6f927659783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available:  False\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"GPU available: \", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l62yWQQk2rhh"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, transform=None, target_transform=None):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        y = self.target[index]\n",
        "        if self.target_transform:\n",
        "            y = self.target_transform(y)\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nX3-UIJgkpK"
      },
      "source": [
        "## Question 1: Data loading and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vr_uvWp4gE-3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-03 18:38:08--  http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n",
            "Resolving www.astro.utoronto.ca (www.astro.utoronto.ca)... 128.100.89.92\n",
            "Connecting to www.astro.utoronto.ca (www.astro.utoronto.ca)|128.100.89.92|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5 [following]\n",
            "--2024-01-03 18:38:08--  https://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n",
            "Connecting to www.astro.utoronto.ca (www.astro.utoronto.ca)|128.100.89.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 210234548 (200M)\n",
            "Saving to: ‘Galaxy10.h5.1’\n",
            "\n",
            "Galaxy10.h5.1       100%[===================>] 200.50M  28.1MB/s    in 7.8s    \n",
            "\n",
            "2024-01-03 18:38:17 (25.6 MB/s) - ‘Galaxy10.h5.1’ saved [210234548/210234548]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['ans', 'images']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## download and read the .h5 data file\n",
        "!wget http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5\n",
        "f = h5py.File('Galaxy10.h5')\n",
        "list(f.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<HDF5 dataset \"images\": shape (21785, 69, 69, 3), type \"|u1\">"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f[\"images\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jVcyTlJduZc5"
      },
      "outputs": [],
      "source": [
        "# First create np.arrays from the data in the file, then make torch.Tensors from those.\n",
        "# Directly going to torch.Tensor would be very slow in this case because h5py provides lazy access to the data, (see https://github.com/pytorch/pytorch/issues/13918).\n",
        "\n",
        "# create numpy arrays for labels and data\n",
        "\n",
        "data = torch.tensor(np.array(f[\"images\"]))\n",
        "labels = torch.tensor(np.array(f[\"ans\"]))\n",
        "\n",
        "# we change the data type and permute the color channel axis from place 3 to 1, to conform with pytorch defaults.\n",
        "data = data.type(torch.float32).permute(0,3,1,2)  # leave this as is\n",
        "labels = labels.type(torch.LongTensor)            # leave this as is"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "snJ48HzvlYnH"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'Tensor' object is not callable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m crop \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mRandomCrop((\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m))\n\u001b[1;32m      5\u001b[0m samples \u001b[38;5;241m=\u001b[39m data[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;241m1000\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), :, :, :]\n\u001b[0;32m----> 6\u001b[0m cropped_samples \u001b[38;5;241m=\u001b[39m \u001b[43mcrop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# compute the channel means and std's on samples\u001b[39;00m\n",
            "File \u001b[0;32m~/miniforge3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:898\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    897\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[0;32m--> 898\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
          ]
        }
      ],
      "source": [
        "# continue with computing the channel means and std's after cropping on a subset of the data\n",
        "\n",
        "# random cropped samples\n",
        "crop = transforms.RandomCrop((48,48))\n",
        "samples = data[np.random.choice(len(data), 1000, replace=False), :, :, :]\n",
        "cropped_samples = crop.apply(samples)\n",
        "\n",
        "# compute the channel means and std's on samples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1000, 3, 69, 69])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok1XodJgmBw-"
      },
      "outputs": [],
      "source": [
        "# define the composed transform\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLQppswimGF6"
      },
      "outputs": [],
      "source": [
        "# create train and test datasets for the two tasks as instances of the MyDataset class, e.g.\n",
        "# example_dataset = MyDataset(example_data, example_labels, transform=example_transform)\n",
        "\n",
        "# then create data loaders with batch size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWbSzEmQgvBV"
      },
      "source": [
        "## Question 2: Fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG_1tPcxgEko"
      },
      "outputs": [],
      "source": [
        "# define and train the FCN\n",
        "\n",
        "# Hint: Define train() and test() functions which you can reuse for the other models in the later questions\n",
        "#       (as done in the exercise sessions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQmjIgAWhwdQ"
      },
      "source": [
        "## Question 3: Convolutional network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbO8qfqIh1Mp"
      },
      "outputs": [],
      "source": [
        "# Define and train the CNN\n",
        "\n",
        "# Compare test accuracies of FCN and CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZx17cqmiDad"
      },
      "source": [
        "## Question 4: Confusion matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi-2JeC2iICE"
      },
      "outputs": [],
      "source": [
        "# Compute and plot the confusion matrices of the FCN and CNN. Comment on the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zCCqmjUikWU"
      },
      "source": [
        "## Question 5: Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaMRwxgoiqSW"
      },
      "outputs": [],
      "source": [
        "# Re-use the frozen cnn_backbone from Q4 with a new classification head, training on the two unseen classes."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
