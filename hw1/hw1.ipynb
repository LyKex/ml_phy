{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n",
    "Download and read csv file. The column names are determined according to data file readme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features_0</th>\n",
       "      <th>features_1</th>\n",
       "      <th>features_2</th>\n",
       "      <th>features_3</th>\n",
       "      <th>features_4</th>\n",
       "      <th>features_5</th>\n",
       "      <th>features_6</th>\n",
       "      <th>features_7</th>\n",
       "      <th>features_8</th>\n",
       "      <th>features_9</th>\n",
       "      <th>features_10</th>\n",
       "      <th>features_11</th>\n",
       "      <th>features_12</th>\n",
       "      <th>features_13</th>\n",
       "      <th>features_14</th>\n",
       "      <th>features_15</th>\n",
       "      <th>features_16</th>\n",
       "      <th>features_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972861</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>1.176225</td>\n",
       "      <td>1.157156</td>\n",
       "      <td>-1.739873</td>\n",
       "      <td>-0.874309</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-0.252552</td>\n",
       "      <td>1.921887</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.410772</td>\n",
       "      <td>1.145621</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.367815</td>\n",
       "      <td>0.040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667973</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>-1.225171</td>\n",
       "      <td>0.506102</td>\n",
       "      <td>-0.338939</td>\n",
       "      <td>1.672543</td>\n",
       "      <td>3.475464</td>\n",
       "      <td>-1.219136</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>3.775174</td>\n",
       "      <td>1.045977</td>\n",
       "      <td>0.568051</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448410</td>\n",
       "      <td>0.205356</td>\n",
       "      <td>1.321893</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444840</td>\n",
       "      <td>-0.134298</td>\n",
       "      <td>-0.709972</td>\n",
       "      <td>0.451719</td>\n",
       "      <td>-1.613871</td>\n",
       "      <td>-0.768661</td>\n",
       "      <td>1.219918</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>1.831248</td>\n",
       "      <td>-0.431385</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.941514</td>\n",
       "      <td>1.587535</td>\n",
       "      <td>2.024308</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>1.562374</td>\n",
       "      <td>1.135454</td>\n",
       "      <td>0.180910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>-0.976145</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>-0.677328</td>\n",
       "      <td>2.033060</td>\n",
       "      <td>1.533041</td>\n",
       "      <td>3.046260</td>\n",
       "      <td>-1.005285</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>1.015211</td>\n",
       "      <td>1.582217</td>\n",
       "      <td>1.551914</td>\n",
       "      <td>0.761215</td>\n",
       "      <td>1.715464</td>\n",
       "      <td>1.492257</td>\n",
       "      <td>0.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309996</td>\n",
       "      <td>-0.690089</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>1.589283</td>\n",
       "      <td>-0.693326</td>\n",
       "      <td>0.622907</td>\n",
       "      <td>1.087562</td>\n",
       "      <td>-0.381742</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>1.365479</td>\n",
       "      <td>1.179295</td>\n",
       "      <td>0.968218</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083158</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>1.154854</td>\n",
       "      <td>0.094859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853325</td>\n",
       "      <td>-0.961783</td>\n",
       "      <td>-1.487277</td>\n",
       "      <td>0.678190</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>1.647969</td>\n",
       "      <td>1.843867</td>\n",
       "      <td>0.276954</td>\n",
       "      <td>1.025105</td>\n",
       "      <td>-1.486535</td>\n",
       "      <td>0.892879</td>\n",
       "      <td>1.684429</td>\n",
       "      <td>1.674084</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>1.046707</td>\n",
       "      <td>2.646649</td>\n",
       "      <td>1.389226</td>\n",
       "      <td>0.364599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951581</td>\n",
       "      <td>0.139370</td>\n",
       "      <td>1.436884</td>\n",
       "      <td>0.880440</td>\n",
       "      <td>-0.351948</td>\n",
       "      <td>-0.740852</td>\n",
       "      <td>0.290863</td>\n",
       "      <td>-0.732360</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.257738</td>\n",
       "      <td>0.802871</td>\n",
       "      <td>0.545319</td>\n",
       "      <td>0.602730</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.748959</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>0.443471</td>\n",
       "      <td>0.239953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840389</td>\n",
       "      <td>1.419162</td>\n",
       "      <td>-1.218766</td>\n",
       "      <td>1.195631</td>\n",
       "      <td>1.695645</td>\n",
       "      <td>0.663756</td>\n",
       "      <td>0.490888</td>\n",
       "      <td>-0.509186</td>\n",
       "      <td>0.704289</td>\n",
       "      <td>0.045744</td>\n",
       "      <td>0.825015</td>\n",
       "      <td>0.723530</td>\n",
       "      <td>0.778236</td>\n",
       "      <td>0.752942</td>\n",
       "      <td>0.838953</td>\n",
       "      <td>0.614048</td>\n",
       "      <td>1.210595</td>\n",
       "      <td>0.026692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.784218</td>\n",
       "      <td>-0.833565</td>\n",
       "      <td>-0.560091</td>\n",
       "      <td>0.953342</td>\n",
       "      <td>-0.688969</td>\n",
       "      <td>-1.428233</td>\n",
       "      <td>2.660703</td>\n",
       "      <td>-0.861344</td>\n",
       "      <td>2.116892</td>\n",
       "      <td>2.906151</td>\n",
       "      <td>1.232334</td>\n",
       "      <td>0.952444</td>\n",
       "      <td>0.685846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781874</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>1.197807</td>\n",
       "      <td>0.093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.680454</td>\n",
       "      <td>-1.186213</td>\n",
       "      <td>1.043521</td>\n",
       "      <td>-0.316755</td>\n",
       "      <td>0.246879</td>\n",
       "      <td>1.120280</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>1.640881</td>\n",
       "      <td>-0.797688</td>\n",
       "      <td>0.854212</td>\n",
       "      <td>1.121858</td>\n",
       "      <td>1.165438</td>\n",
       "      <td>1.498351</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>1.293524</td>\n",
       "      <td>1.539167</td>\n",
       "      <td>0.187496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  features_0  features_1  features_2  features_3  features_4  \\\n",
       "0          0.0    0.972861    0.653855    1.176225    1.157156   -1.739873   \n",
       "1          1.0    1.667973    0.064191   -1.225171    0.506102   -0.338939   \n",
       "2          1.0    0.444840   -0.134298   -0.709972    0.451719   -1.613871   \n",
       "3          1.0    0.381256   -0.976145    0.693152    0.448959    0.891753   \n",
       "4          1.0    1.309996   -0.690089   -0.676259    1.589283   -0.693326   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "4999995    1.0    0.853325   -0.961783   -1.487277    0.678190    0.493580   \n",
       "4999996    0.0    0.951581    0.139370    1.436884    0.880440   -0.351948   \n",
       "4999997    0.0    0.840389    1.419162   -1.218766    1.195631    1.695645   \n",
       "4999998    1.0    1.784218   -0.833565   -0.560091    0.953342   -0.688969   \n",
       "4999999    0.0    0.761500    0.680454   -1.186213    1.043521   -0.316755   \n",
       "\n",
       "         features_5  features_6  features_7  features_8  features_9  \\\n",
       "0         -0.874309    0.567765   -0.175000    0.810061   -0.252552   \n",
       "1          1.672543    3.475464   -1.219136    0.012955    3.775174   \n",
       "2         -0.768661    1.219918    0.504026    1.831248   -0.431385   \n",
       "3         -0.677328    2.033060    1.533041    3.046260   -1.005285   \n",
       "4          0.622907    1.087562   -0.381742    0.589204    1.365479   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "4999995    1.647969    1.843867    0.276954    1.025105   -1.486535   \n",
       "4999996   -0.740852    0.290863   -0.732360    0.001360    0.257738   \n",
       "4999997    0.663756    0.490888   -0.509186    0.704289    0.045744   \n",
       "4999998   -1.428233    2.660703   -0.861344    2.116892    2.906151   \n",
       "4999999    0.246879    1.120280    0.998479    1.640881   -0.797688   \n",
       "\n",
       "         features_10  features_11  features_12  features_13  features_14  \\\n",
       "0           1.921887     0.889637     0.410772     1.145621     1.932632   \n",
       "1           1.045977     0.568051     0.481928     0.000000     0.448410   \n",
       "2           0.526283     0.941514     1.587535     2.024308     0.603498   \n",
       "3           0.569386     1.015211     1.582217     1.551914     0.761215   \n",
       "4           1.179295     0.968218     0.728563     0.000000     1.083158   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "4999995     0.892879     1.684429     1.674084     3.366298     1.046707   \n",
       "4999996     0.802871     0.545319     0.602730     0.002998     0.748959   \n",
       "4999997     0.825015     0.723530     0.778236     0.752942     0.838953   \n",
       "4999998     1.232334     0.952444     0.685846     0.000000     0.781874   \n",
       "4999999     0.854212     1.121858     1.165438     1.498351     0.931580   \n",
       "\n",
       "         features_15  features_16  features_17  \n",
       "0           0.994464     1.367815     0.040714  \n",
       "1           0.205356     1.321893     0.377584  \n",
       "2           1.562374     1.135454     0.180910  \n",
       "3           1.715464     1.492257     0.090719  \n",
       "4           0.043429     1.154854     0.094859  \n",
       "...              ...          ...          ...  \n",
       "4999995     2.646649     1.389226     0.364599  \n",
       "4999996     0.401166     0.443471     0.239953  \n",
       "4999997     0.614048     1.210595     0.026692  \n",
       "4999998     0.676003     1.197807     0.093689  \n",
       "4999999     1.293524     1.539167     0.187496  \n",
       "\n",
       "[5000000 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"label\"] + [\"features_{}\".format(i) for i in range(18)]\n",
    "df = pd.read_csv(\"SUSY.csv.gz\", index_col=None, header=None, names=names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18 features, and 5000000 data points. The first column is the label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"label\"] == 0.0, \"label\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features_0</th>\n",
       "      <th>features_1</th>\n",
       "      <th>features_2</th>\n",
       "      <th>features_3</th>\n",
       "      <th>features_4</th>\n",
       "      <th>features_5</th>\n",
       "      <th>features_6</th>\n",
       "      <th>features_7</th>\n",
       "      <th>features_8</th>\n",
       "      <th>features_9</th>\n",
       "      <th>features_10</th>\n",
       "      <th>features_11</th>\n",
       "      <th>features_12</th>\n",
       "      <th>features_13</th>\n",
       "      <th>features_14</th>\n",
       "      <th>features_15</th>\n",
       "      <th>features_16</th>\n",
       "      <th>features_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.972861</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>1.176225</td>\n",
       "      <td>1.157156</td>\n",
       "      <td>-1.739873</td>\n",
       "      <td>-0.874309</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-0.252552</td>\n",
       "      <td>1.921887</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.410772</td>\n",
       "      <td>1.145621</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.367815</td>\n",
       "      <td>0.040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667973</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>-1.225171</td>\n",
       "      <td>0.506102</td>\n",
       "      <td>-0.338939</td>\n",
       "      <td>1.672543</td>\n",
       "      <td>3.475464</td>\n",
       "      <td>-1.219136</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>3.775174</td>\n",
       "      <td>1.045977</td>\n",
       "      <td>0.568051</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448410</td>\n",
       "      <td>0.205356</td>\n",
       "      <td>1.321893</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444840</td>\n",
       "      <td>-0.134298</td>\n",
       "      <td>-0.709972</td>\n",
       "      <td>0.451719</td>\n",
       "      <td>-1.613871</td>\n",
       "      <td>-0.768661</td>\n",
       "      <td>1.219918</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>1.831248</td>\n",
       "      <td>-0.431385</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.941514</td>\n",
       "      <td>1.587535</td>\n",
       "      <td>2.024308</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>1.562374</td>\n",
       "      <td>1.135454</td>\n",
       "      <td>0.180910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>-0.976145</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>-0.677328</td>\n",
       "      <td>2.033060</td>\n",
       "      <td>1.533041</td>\n",
       "      <td>3.046260</td>\n",
       "      <td>-1.005285</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>1.015211</td>\n",
       "      <td>1.582217</td>\n",
       "      <td>1.551914</td>\n",
       "      <td>0.761215</td>\n",
       "      <td>1.715464</td>\n",
       "      <td>1.492257</td>\n",
       "      <td>0.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309996</td>\n",
       "      <td>-0.690089</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>1.589283</td>\n",
       "      <td>-0.693326</td>\n",
       "      <td>0.622907</td>\n",
       "      <td>1.087562</td>\n",
       "      <td>-0.381742</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>1.365479</td>\n",
       "      <td>1.179295</td>\n",
       "      <td>0.968218</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083158</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>1.154854</td>\n",
       "      <td>0.094859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853325</td>\n",
       "      <td>-0.961783</td>\n",
       "      <td>-1.487277</td>\n",
       "      <td>0.678190</td>\n",
       "      <td>0.493580</td>\n",
       "      <td>1.647969</td>\n",
       "      <td>1.843867</td>\n",
       "      <td>0.276954</td>\n",
       "      <td>1.025105</td>\n",
       "      <td>-1.486535</td>\n",
       "      <td>0.892879</td>\n",
       "      <td>1.684429</td>\n",
       "      <td>1.674084</td>\n",
       "      <td>3.366298</td>\n",
       "      <td>1.046707</td>\n",
       "      <td>2.646649</td>\n",
       "      <td>1.389226</td>\n",
       "      <td>0.364599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.951581</td>\n",
       "      <td>0.139370</td>\n",
       "      <td>1.436884</td>\n",
       "      <td>0.880440</td>\n",
       "      <td>-0.351948</td>\n",
       "      <td>-0.740852</td>\n",
       "      <td>0.290863</td>\n",
       "      <td>-0.732360</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.257738</td>\n",
       "      <td>0.802871</td>\n",
       "      <td>0.545319</td>\n",
       "      <td>0.602730</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.748959</td>\n",
       "      <td>0.401166</td>\n",
       "      <td>0.443471</td>\n",
       "      <td>0.239953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.840389</td>\n",
       "      <td>1.419162</td>\n",
       "      <td>-1.218766</td>\n",
       "      <td>1.195631</td>\n",
       "      <td>1.695645</td>\n",
       "      <td>0.663756</td>\n",
       "      <td>0.490888</td>\n",
       "      <td>-0.509186</td>\n",
       "      <td>0.704289</td>\n",
       "      <td>0.045744</td>\n",
       "      <td>0.825015</td>\n",
       "      <td>0.723530</td>\n",
       "      <td>0.778236</td>\n",
       "      <td>0.752942</td>\n",
       "      <td>0.838953</td>\n",
       "      <td>0.614048</td>\n",
       "      <td>1.210595</td>\n",
       "      <td>0.026692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.784218</td>\n",
       "      <td>-0.833565</td>\n",
       "      <td>-0.560091</td>\n",
       "      <td>0.953342</td>\n",
       "      <td>-0.688969</td>\n",
       "      <td>-1.428233</td>\n",
       "      <td>2.660703</td>\n",
       "      <td>-0.861344</td>\n",
       "      <td>2.116892</td>\n",
       "      <td>2.906151</td>\n",
       "      <td>1.232334</td>\n",
       "      <td>0.952444</td>\n",
       "      <td>0.685846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.781874</td>\n",
       "      <td>0.676003</td>\n",
       "      <td>1.197807</td>\n",
       "      <td>0.093689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.680454</td>\n",
       "      <td>-1.186213</td>\n",
       "      <td>1.043521</td>\n",
       "      <td>-0.316755</td>\n",
       "      <td>0.246879</td>\n",
       "      <td>1.120280</td>\n",
       "      <td>0.998479</td>\n",
       "      <td>1.640881</td>\n",
       "      <td>-0.797688</td>\n",
       "      <td>0.854212</td>\n",
       "      <td>1.121858</td>\n",
       "      <td>1.165438</td>\n",
       "      <td>1.498351</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>1.293524</td>\n",
       "      <td>1.539167</td>\n",
       "      <td>0.187496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  features_0  features_1  features_2  features_3  features_4  \\\n",
       "0         -1.0    0.972861    0.653855    1.176225    1.157156   -1.739873   \n",
       "1          1.0    1.667973    0.064191   -1.225171    0.506102   -0.338939   \n",
       "2          1.0    0.444840   -0.134298   -0.709972    0.451719   -1.613871   \n",
       "3          1.0    0.381256   -0.976145    0.693152    0.448959    0.891753   \n",
       "4          1.0    1.309996   -0.690089   -0.676259    1.589283   -0.693326   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "4999995    1.0    0.853325   -0.961783   -1.487277    0.678190    0.493580   \n",
       "4999996   -1.0    0.951581    0.139370    1.436884    0.880440   -0.351948   \n",
       "4999997   -1.0    0.840389    1.419162   -1.218766    1.195631    1.695645   \n",
       "4999998    1.0    1.784218   -0.833565   -0.560091    0.953342   -0.688969   \n",
       "4999999   -1.0    0.761500    0.680454   -1.186213    1.043521   -0.316755   \n",
       "\n",
       "         features_5  features_6  features_7  features_8  features_9  \\\n",
       "0         -0.874309    0.567765   -0.175000    0.810061   -0.252552   \n",
       "1          1.672543    3.475464   -1.219136    0.012955    3.775174   \n",
       "2         -0.768661    1.219918    0.504026    1.831248   -0.431385   \n",
       "3         -0.677328    2.033060    1.533041    3.046260   -1.005285   \n",
       "4          0.622907    1.087562   -0.381742    0.589204    1.365479   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "4999995    1.647969    1.843867    0.276954    1.025105   -1.486535   \n",
       "4999996   -0.740852    0.290863   -0.732360    0.001360    0.257738   \n",
       "4999997    0.663756    0.490888   -0.509186    0.704289    0.045744   \n",
       "4999998   -1.428233    2.660703   -0.861344    2.116892    2.906151   \n",
       "4999999    0.246879    1.120280    0.998479    1.640881   -0.797688   \n",
       "\n",
       "         features_10  features_11  features_12  features_13  features_14  \\\n",
       "0           1.921887     0.889637     0.410772     1.145621     1.932632   \n",
       "1           1.045977     0.568051     0.481928     0.000000     0.448410   \n",
       "2           0.526283     0.941514     1.587535     2.024308     0.603498   \n",
       "3           0.569386     1.015211     1.582217     1.551914     0.761215   \n",
       "4           1.179295     0.968218     0.728563     0.000000     1.083158   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "4999995     0.892879     1.684429     1.674084     3.366298     1.046707   \n",
       "4999996     0.802871     0.545319     0.602730     0.002998     0.748959   \n",
       "4999997     0.825015     0.723530     0.778236     0.752942     0.838953   \n",
       "4999998     1.232334     0.952444     0.685846     0.000000     0.781874   \n",
       "4999999     0.854212     1.121858     1.165438     1.498351     0.931580   \n",
       "\n",
       "         features_15  features_16  features_17  \n",
       "0           0.994464     1.367815     0.040714  \n",
       "1           0.205356     1.321893     0.377584  \n",
       "2           1.562374     1.135454     0.180910  \n",
       "3           1.715464     1.492257     0.090719  \n",
       "4           0.043429     1.154854     0.094859  \n",
       "...              ...          ...          ...  \n",
       "4999995     2.646649     1.389226     0.364599  \n",
       "4999996     0.401166     0.443471     0.239953  \n",
       "4999997     0.614048     1.210595     0.026692  \n",
       "4999998     0.676003     1.197807     0.093689  \n",
       "4999999     1.293524     1.539167     0.187496  \n",
       "\n",
       "[5000000 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.4, random_state=42)\n",
    "test, validation = train_test_split(test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n",
      "1000000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test[\"label\"]\n",
    "\n",
    "X_validation = validation.iloc[:, 1:]\n",
    "y_validation = validation[\"label\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5\n",
    "\n",
    "If fitted on test and validation set, some of the distribution of the data will be known to the model. This is a data leakage and may cause overtraining and overestimation of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "X_validation_std = scaler.transform(X_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.27011882e-16,  1.89951758e-18,  1.87228011e-18,  4.21109074e-17,\n",
       "       -2.77845894e-17, -3.73413892e-17, -4.48470890e-17, -1.87678021e-17,\n",
       "       -8.04599646e-16,  6.58791540e-18, -7.71661253e-17, -1.92949064e-16,\n",
       "       -1.20894110e-16, -3.56024543e-16,  3.20129108e-17, -1.17697851e-16,\n",
       "       -4.21969778e-15,  6.84624505e-16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_strength = 0.1\n",
    "\n",
    "def class_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_classification(X, y, reg_strength):\n",
    "    return np.linalg.inv(X.T @ X + reg_strength * np.eye(X.shape[1])) @ X.T @ y\n",
    "\n",
    "def ridge_predict(X, w):\n",
    "    return np.sign(X @ w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ridge = ridge_classification(X_train_std, Y_train, reg_strength)\n",
    "\n",
    "acc_ridge = class_accuracy(y_test, ridge_predict(X_test_std, w_ridge))\n",
    "print(\"accuracy of ridge regression on test set: {}\".format(acc_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8\n",
    "\n",
    "`sklearn` implementation:\n",
    "$$\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C = 1/reg_strength, fit_intercept=False)\n",
    "logreg.fit(X_train_std, y_train)\n",
    "acc_reglog = accuracy(y_test, logreg.predict(X_test_std))\n",
    "print(\"accuracy of logistic regression on test set: {}\".format(acc_reglog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-1, 4, 10)\n",
    "\n",
    "for l in lambdas:\n",
    "    w_ridge = ridge_classification(X_train_std, y_train, l)\n",
    "    acc_ridge_train = class_accuracy(y_train, ridge_predict(X_train_std, w_ridge))\n",
    "    acc_ridge_val = class_accuracy(y_validation, ridge_predict(X_validation_std, w_ridge))\n",
    "\n",
    "    logreg = LogisticRegression(C = 1/l, fit_intercept=False)\n",
    "    logreg.fit(X_train_std, y_train)\n",
    "    acc_logreg_train = class_accuracy(y_train, logreg.predict(X_train_std))\n",
    "    acc_logreg_val = class_accuracy(y_validation, logreg.predict(X_validation_std))\n",
    "\n",
    "    print(\">>> lambda: \", l)\n",
    "    print(\"ridge classification train accuracy: \", acc_ridge_train)\n",
    "    print(\"ridge classification validation accuracy: \", acc_ridge_val)\n",
    "    print(\"logistic regression train accuracy: \", acc_logreg_train)\n",
    "    print(\"logreg regression validation accuracy: \", acc_logreg_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss is a better indication of the model performance, since it better describes the model predictive ability on unseen data and therefore generalizability. \n",
    "\n",
    "Thus, $\\lambda =$ is the best value of the range for ridge classification since it yields lowest validation loss. Similarly, $\\lambda =$ is the optimal value for logistic regression.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
